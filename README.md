# Oviya - Emotional Intelligence AI Companion

> *"Hey, I'm Ovia, your emotional intelligence companion. That means I'm here to help you navigate those wild and wonderful emotions we all feel."*

Oviya is a real-time voice AI companion that provides empathetic, emotionally-aware conversations. Built with a 4-layer architecture combining advanced AI models for natural human-like interaction.

## ğŸ—ï¸ Project Structure

```
oviya/
â”œâ”€â”€ core/                          # Shared core components
â”‚   â”œâ”€â”€ brain/                    # LLM brain components (personality, safety, etc.)
â”‚   â”œâ”€â”€ voice/                    # Voice processing (TTS, prosody, etc.)
â”‚   â”œâ”€â”€ data/                     # Data processing & bias filtering
â”‚   â”œâ”€â”€ monitoring/               # Analytics & metrics
â”‚   â”œâ”€â”€ validation/               # Emotion validation
â”‚   â”œâ”€â”€ serving/                  # API endpoints
â”‚   â””â”€â”€ rlhf/                     # Reinforcement learning
â”‚
â”œâ”€â”€ production/                   # Main production system (monolithic)
â”‚   â”œâ”€â”€ brain/                    # Production brain (uses core + extensions)
â”‚   â”œâ”€â”€ voice/                    # Production voice (uses core + extensions)
â”‚   â”œâ”€â”€ emotion_detector/         # Emotion detection
â”‚   â”œâ”€â”€ emotion_controller/       # Emotion mapping & control
â”‚   â”œâ”€â”€ websocket_server.py      # WebSocket API server
â”‚   â”œâ”€â”€ realtime_conversation.py  # Real-time pipeline
â”‚   â””â”€â”€ docker-compose.yml        # Production deployment
â”‚
â”œâ”€â”€ services/                     # Alternative microservices architecture
â”‚   â”œâ”€â”€ asr/                      # Speech recognition service
â”‚   â”œâ”€â”€ vad/                      # Voice activity detection
â”‚   â”œâ”€â”€ csm/                      # Voice synthesis service
â”‚   â”œâ”€â”€ orchestrator/             # Request orchestration
â”‚   â””â”€â”€ docker-compose.yml        # Services deployment
â”‚
â”œâ”€â”€ clients/                      # Client applications
â”‚   â”œâ”€â”€ mobile/                   # React Native mobile app
â”‚   â”œâ”€â”€ web/                      # Web client
â”‚   â”œâ”€â”€ website/                  # Public website
â”‚   â””â”€â”€ admin/                    # Admin interface
â”‚
â”œâ”€â”€ corpus/                       # Data processing pipeline
â”‚   â”œâ”€â”€ raw/                      # Raw emotional datasets
â”‚   â”œâ”€â”€ processed/                # Processed training data
â”‚   â””â”€â”€ scripts/                  # Processing scripts
â”‚
â”œâ”€â”€ shared/                       # Infrastructure & deployment
â”‚   â”œâ”€â”€ docker/                   # Docker configurations
â”‚   â”œâ”€â”€ k8s/                      # Kubernetes manifests
â”‚   â””â”€â”€ ci/                       # CI/CD pipelines
â”‚
â”œâ”€â”€ tests/                        # Integration tests
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ docker-compose.yml            # Development orchestration
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### Option 1: Production System (Recommended)

```bash
# 1. Install Ollama locally
brew install ollama
ollama serve &
ollama pull qwen2.5:7b

# 2. Start production system
cd production
docker-compose up -d

# 3. Access at http://localhost:8000
```

### Option 2: Development Setup

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Set environment variables
cp production/.env production/.env.local
# Edit .env.local with your service URLs

# 3. Run locally
cd production
python websocket_server.py
```

### Option 3: Microservices Architecture

```bash
cd services
docker-compose up -d
```

## ğŸ¯ Architecture Overview

### Production System (Monolithic)
- **WebSocket Server**: Real-time bidirectional communication
- **4-Layer Pipeline**:
  1. **Emotion Detector**: Analyzes user emotional state
  2. **Brain (LLM)**: Generates empathetic responses
  3. **Emotion Controller**: Maps emotions to acoustic parameters
  4. **Voice Engine**: Synthesizes emotional speech

### Microservices Alternative
- **ASR Service**: Speech-to-text processing
- **VAD Service**: Voice activity detection
- **CSM Service**: Voice synthesis
- **Orchestrator**: Request coordination

## ğŸ› ï¸ Key Components

### Core Shared Libraries
- **Bias Filtering**: Cultural sensitivity and safety
- **Personality System**: Long-term relationship memory
- **Prosody Engine**: Natural speech patterns
- **Monitoring**: Performance analytics

### Voice & Audio
- **CSM-1B**: Conversational speech synthesis
- **OpenVoice V2**: Voice cloning and fine control
- **Real-time Processing**: <500ms transcription latency

### Brain & Intelligence
- **Qwen2.5:7B**: Primary LLM for responses
- **49 Emotion Taxonomy**: Comprehensive emotional range
- **Context Awareness**: Conversation history and memory

## ğŸ“Š Performance

- **Transcription**: <500ms latency
- **Brain Processing**: <1.5s response time
- **Voice Synthesis**: <2s total
- **End-to-end**: <4s conversational turn

## ğŸ”§ Configuration

Environment variables control service endpoints:

```bash
# LLM Service
OLLAMA_URL=http://localhost:11434/api/generate

# Voice Services
CSM_URL=http://localhost:19517/generate
CSM_STREAM_URL=http://localhost:19517/generate/stream

# Speech Recognition
WHISPERX_URL=http://localhost:1111
```

## ğŸ§ª Testing

```bash
# Run integration tests
python -m pytest tests/

# Test production system
cd production
python production_sanity_tests.py

# Test specific scenarios
python tests/test_5_scenarios.py
```

## ğŸ“¦ Deployment Options

### Docker (Recommended)
```bash
# Production deployment
cd production
docker-compose up -d

# Development with local Ollama
docker-compose --profile with-ollama up -d
```

### Kubernetes
```yaml
# Use manifests in shared/k8s/
kubectl apply -f shared/k8s/
```

## ğŸ¤ Contributing

1. **Core Components**: Changes to `core/` affect all systems
2. **Production**: Main development in `production/`
3. **Services**: Microservices development in `services/`
4. **Clients**: UI/UX development in `clients/`

## ğŸ“„ License

See individual component licenses.

## ğŸ”— Links

- [Architecture Documentation](production/README.md)
- [API Reference](production/websocket_server.py)
- [Client Integration](clients/README.md)


