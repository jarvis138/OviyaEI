# Oviya EI - Emotional Intelligence Companion

> A speech-to-speech native, emotionally intelligent AI companion designed for professional mental health support with clinical safety standards and comprehensive governance frameworks.

## ğŸ¯ Overview

Oviya EI is an advanced therapeutic AI system that combines:
- **CSM-1B Conversational Speech Model** - Ultra-low latency, emotional voice synthesis with RVQ streaming
- **Mimi Codec** - Real-time audio decoding for natural conversations
- **18 Therapeutic Frameworks** - CBT, DBT, EFT, Rogerian, and more integrated into LLM responses
- **5-Pillar Personality System** - Ma, Ahimsa, Jeong, Logos, Lagom influencing prosody and responses
- **26+ MCP Servers** - Specialized modules for mental health support, thinking, and therapy
- **Unified VAD+STT Pipeline** - Optimized Silero VAD and Whisper v3 Turbo for real-time speech processing
- **Clinical Safety & Governance** - HIPAA compliance, crisis detection, monitoring

## ğŸ—ï¸ Architecture

### 4-Layer Architecture

1. **ğŸ­ Therapeutic Brain Layer**
   - **LLM**: Ollama + Llama 3.2:3B for response generation
   - **18 Therapeutic Frameworks**: CBT, DBT, EFT, Rogerian, Attachment Theory, Secure Base, etc.
   - **Cultural Wisdom**: Ma (Japanese), Jeong (Korean), Ahimsa (Indian), Logos (Greek), Lagom (Scandinavian)
   - **Memory Systems**: ChromaDB for long-term memory and personality evolution
   - **Emotional Intelligence**: Emotion embeddings, temporal tracking, emotional reasoning

2. **ğŸµ Voice Synthesis Layer**
   - **CSM-1B**: Conversational speech model with RVQ-level streaming
   - **Mimi Codec**: Real-time audio decoding from RVQ tokens
   - **Prosody Engine**: Personality-driven voice modulation (pitch, rate, energy)
   - **Emotion References**: Multi-TTS emotion reference system for CSM-1B conditioning
   - **Unified VAD+STT**: Silero VAD + Whisper v3 Turbo for speech processing

3. **ğŸ›¡ï¸ Safety & Governance Layer**
   - **Crisis Detection**: AI Therapist MCP integration for mental health safety
   - **PII Redaction**: HIPAA-compliant privacy protection
   - **Therapeutic Boundaries**: Ethical AI-human interaction limits
   - **Audit Trails**: Complete logging for clinical oversight

4. **ğŸ”¬ MCP Ecosystem Layer**
   - **AI Therapist MCP**: Crisis intervention, coping strategies, positive affirmations
   - **MCP Thinking**: Enhanced sequential thinking, dialectical reasoning
   - **26+ MCP Servers**: Mental health, psychology, cultural adaptation

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- CUDA-capable GPU (recommended for CSM-1B)
- Ollama with Llama 3.2:3B model installed
- HuggingFace account with API token

### Installation

```bash
# Clone repository
git clone <repository-url>
cd "Oviya EI"

# Install dependencies
cd production
pip install -r requirements.txt

# Setup environment
export HUGGINGFACE_TOKEN="your_token_here"
export OVIYA_SECRET="your_secret_key"

# Verify CSM-1B installation (optional)
python3 verify_csm_installation.py
```

### Run Server

```bash
cd production
python3 websocket_server.py
```

The server will start on `http://localhost:8000` with WebSocket support at `ws://localhost:8000/ws`.

## ğŸ“ Project Structure

```
Oviya EI/
â”œâ”€â”€ production/              # Main production codebase
â”‚   â”œâ”€â”€ brain/              # Therapeutic intelligence
â”‚   â”‚   â”œâ”€â”€ llm_brain.py   # Main LLM brain with 18 frameworks
â”‚   â”‚   â”œâ”€â”€ crisis_detection.py
â”‚   â”‚   â”œâ”€â”€ empathic_thinking.py
â”‚   â”‚   â”œâ”€â”€ emotional_reciprocity.py
â”‚   â”‚   â””â”€â”€ ...            # 20+ brain modules
â”‚   â”œâ”€â”€ voice/             # Voice synthesis
â”‚   â”‚   â”œâ”€â”€ csm_1b_stream.py      # CSM-1B RVQ streaming
â”‚   â”‚   â”œâ”€â”€ unified_vad_stt.py    # VAD+STT pipeline
â”‚   â”‚   â”œâ”€â”€ emotion_controller.py
â”‚   â”‚   â”œâ”€â”€ prosody_engine.py
â”‚   â”‚   â””â”€â”€ ...            # Voice processing modules
â”‚   â”œâ”€â”€ websocket_server.py        # Main WebSocket server
â”‚   â”œâ”€â”€ voice_server_webrtc.py     # WebRTC server (alternative)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ clients/               # Client applications
â”‚   â”œâ”€â”€ web/              # Next.js web client
â”‚   â”œâ”€â”€ mobile/           # React Native mobile app
â”‚   â””â”€â”€ admin/            # Admin dashboard
â”œâ”€â”€ services/             # Microservices
â”‚   â””â”€â”€ services/         # ASR, TTS, orchestration services
â”œâ”€â”€ mcp-ecosystem/        # MCP servers
â”‚   â””â”€â”€ servers/          # 26+ MCP servers
â”œâ”€â”€ core/                 # Core modules
â””â”€â”€ corpus/               # Training data
```

## ğŸ”§ Key Features

### Speech-to-Speech Native
- **Unified VAD+STT Pipeline**: Silero VAD (ONNX optimized) + Whisper v3 Turbo (`faster-whisper`)
- **Real-time Audio Processing**: User audio captured, processed, and used for conversation context
- **CSM-1B RVQ Streaming**: Ultra-low latency (<120ms) voice generation with RVQ tokens
- **Mimi Decode**: Real-time audio decoding from RVQ tokens to PCM audio
- **User Audio Context**: User's spoken audio included in CSM-1B conversation context

### Emotional Intelligence
- **Emotion Detection**: Text-based and acoustic emotion detection
- **Emotion Library**: 28+ emotions across 3 tiers (Tier 1: Core, Tier 2: Nuanced, Tier 3: Complex)
- **Emotion Blender**: Emotion interpolation for expanded emotional range
- **Temporal Emotion Tracking**: Track emotion patterns over time
- **Emotional Reasoning**: Advanced emotional reasoning and inference
- **Emotion Embeddings**: Real audio/text-based embeddings for emotional intelligence

### Therapeutic Systems
- **18 Therapeutic Frameworks**: 
  - CBT, DBT, EFT, Rogerian (Person-Centered)
  - Attachment Theory, Secure Base Theory
  - Unconditional Positive Regard
  - Vulnerability Reciprocation
  - Strategic Silence (Ma - é–“)
  - Empathic Thinking, Emotional Reciprocity
  - Crisis Intervention, Micro-Affirmations
  - Healthy Boundaries, Epistemic Prosody
  - Emotion Transition Smoothing, Backchannel System
- **Crisis Detection**: AI Therapist MCP integration for mental health safety
- **Empathic Thinking**: MCP Thinking server for deep cognitive empathy
- **Memory System**: ChromaDB for long-term therapeutic relationship building

### Cultural Wisdom Integration
- **Ma (Japanese - é–“)**: Contemplative space â†’ slower speech, more pauses
- **Ahimsa (Indian)**: Compassion â†’ warmer, gentler prosody
- **Jeong (Korean)**: Emotional connection â†’ more expressive intonation
- **Logos (Greek)**: Rational grounding â†’ more measured, stable prosody
- **Lagom (Scandinavian)**: Balanced prosody

### Voice Synthesis
- **CSM-1B Integration**: Sesame's conversational speech model
- **Prosody Control**: Personality-driven modulation (pitch_scale, rate_scale, energy_scale)
- **Emotion References**: Multi-TTS emotion reference system (OpenVoiceV2, Coqui TTS, Bark, StyleTTS2)
- **RVQ Streaming**: Token-level streaming for ultra-low latency
- **CUDA Graphs**: Optimization for consistent low-latency performance

## ğŸ“Š Recent Updates (November 2024)

### Codebase Cleanup
- âœ… Removed ~69 redundant files (historical docs, duplicates, old audio)
- âœ… Fixed broken imports (OptimizedCSMStreamer, SessionManager)
- âœ… Consolidated duplicate configurations
- âœ… Optimized codebase structure
- âœ… Created comprehensive backup

### CSM-1B Integration
- âœ… CSM-1B model loading and verification
- âœ… RVQ-level streaming implementation
- âœ… Mimi codec integration for audio decoding
- âœ… Conversation context formatting with audio references
- âœ… Prosody parameter control (pitch, rate, energy)

### Speech-to-Speech Native
- âœ… Unified VAD+STT pipeline (Silero + Whisper)
- âœ… User audio capture and processing
- âœ… User audio included in CSM-1B conversation context
- âœ… Real-time audio streaming

### Emotional Intelligence Enhancements
- âœ… Emotion embeddings system
- âœ… Temporal emotion tracking
- âœ… Emotional reasoning engine
- âœ… Emotion blender and library (28+ emotions)
- âœ… Cultural wisdom integration into prosody

### MCP Integration
- âœ… AI Therapist MCP integration (crisis intervention, coping strategies)
- âœ… MCP Thinking server integration (enhanced thinking, dialectical reasoning)
- âœ… Real MCP client implementation (replacing mock clients)

## ğŸ§ª Testing

```bash
cd production

# Test complete pipeline
python3 test_complete_pipeline.py

# Test CSM-1B integration
python3 tests/test_csm_1b.py

# Test brain systems
python3 tests/test_brain_simple.py

# Test realtime system
python3 tests/test_realtime_system.py
```

## ğŸ“š Documentation

- [Setup Guide](production/SETUP_COMPLETE.md) - Complete setup instructions
- [CSM-1B Verification](production/CSM_1B_VERIFICATION.md) - CSM-1B integration guide
- [Architecture Verification](production/4_LAYER_ARCHITECTURE_VERIFICATION.md) - Architecture details
- [Cleanup Summary](production/CLEANUP_COMPLETE.md) - Codebase cleanup documentation
- [Implementation Status](production/IMPLEMENTATION_COMPLETE.md) - Implementation details

## ğŸ”’ Safety & Compliance

- **HIPAA-Compliant**: PII redaction and privacy protection
- **Clinical Safety**: Crisis detection and intervention protocols
- **Therapeutic Boundaries**: Ethical AI-human interaction limits
- **Audit Trails**: Complete logging for clinical oversight
- **Crisis Resources**: Automatic emergency resource provision

## ğŸ”Œ API Usage

### WebSocket API

```javascript
// Connect to WebSocket
const ws = new WebSocket('ws://localhost:8000/ws');

// Send audio chunk
ws.send(JSON.stringify({
  type: 'audio',
  audio_base64: base64AudioData,
  sample_rate: 16000
}));

// Receive response
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'audio') {
    // Play audio response
    playAudio(data.audio_base64);
  } else if (data.type === 'text') {
    // Display text
    console.log(data.text);
  }
};
```

### Python API

```python
from production.brain.llm_brain import OviyaBrain

# Initialize brain
brain = OviyaBrain()

# Generate therapeutic response
response = brain.think(
    user_message="I'm feeling really anxious about work",
    conversation_history=[],
    memory_triples=[]
)

print(response["text"])  # Therapeutic response
print(response["emotion"])  # Detected emotion
print(response["personality_vector"])  # Personality vector
```

## ğŸ› ï¸ Development

### Key Components

- **`production/websocket_server.py`**: Main WebSocket server for real-time conversations
- **`production/brain/llm_brain.py`**: Core therapeutic intelligence with 18 frameworks
- **`production/voice/csm_1b_stream.py`**: CSM-1B RVQ streaming implementation
- **`production/voice/unified_vad_stt.py`**: Unified VAD+STT pipeline
- **`production/prosody_engine.py`**: Prosody computation for voice modulation

### Adding New Features

1. Create feature branch: `git checkout -b feature/your-feature`
2. Implement following Oviya's architecture patterns
3. Add tests: `production/tests/test_your_feature.py`
4. Update documentation
5. Submit PR with clear description

## ğŸ¤ Contributing

We welcome contributions! Please:
1. Fork the repository
2. Create a feature branch
3. Follow code style and architecture patterns
4. Add tests for new features
5. Submit a pull request

## ğŸ“„ License

[License information]

## ğŸ™ Acknowledgments

- **Sesame AI** - CSM-1B conversational speech model
- **Hugging Face** - Model hosting and infrastructure
- **OpenVoiceV2, Coqui TTS, Bark** - Emotion reference generation
- **MCP Ecosystem** - AI Therapist and Thinking servers
- All open-source contributors

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/oviya-ei/issues)
- **Documentation**: See `production/` directory for detailed docs
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/oviya-ei/discussions)

---

**Status**: âœ… Production Ready  
**Last Updated**: November 2024  
**Version**: 1.0.0

*Built with â¤ï¸ for mental health and emotional intelligence*
