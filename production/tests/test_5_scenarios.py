#!/usr/bin/env python3
"""Test 5 diverse scenarios to showcase all enhancements"""

import sys
from pathlib import Path

# Add root directory to path for imports
ROOT_DIR = Path(__file__).parent.parent.parent
sys.path.insert(0, str(ROOT_DIR))

from production.brain.llm_brain import OviyaBrain
from production.emotion_controller.controller import EmotionController
from production.voice.openvoice_tts import HybridVoiceEngine
import torch
import torchaudio

def test_scenario(num, title, message, emotion, brain, controller, tts):
    print(f"\n{'='*70}")
    print(f"  SCENARIO {num}: {title}")
    print('='*70)
    print(f"User: \"{message}\"")
    print(f"Emotion: {emotion}")
    
    # Brain
    response = brain.think(message, emotion)
    print(f"\nBRAIN:")
    print(f"   Response: \"{response['text']}\"")
    print(f"   Emotion: {response['emotion']} (intensity: {response['intensity']:.2f})")

    if response.get('has_backchannel'):
        print(f"   Backchannel: YES ({response.get('backchannel_type')})")

    if 'epistemic_analysis' in response and response['epistemic_analysis']['epistemic_state'] != 'neutral':
        print(f"   Epistemic: {response['epistemic_analysis']['epistemic_state']}")

    print(f"   Prosody: {response['prosodic_text'][:80]}...")

    # Show emotional state
    if 'emotional_state' in response:
        state = response['emotional_state']
        print(f"   Energy: {state['energy_level']:.2f}, Pace: {state['pace']:.2f}x, Warmth: {state['warmth']:.2f}")
    
    # Controller
    emotion_params = controller.map_emotion(
        response['emotion'],
        response['intensity'],
        response.get('contextual_modifiers')
    )
    
    print(f"\nCONTROLLER:")
    print(f"   Pitch: {emotion_params['pitch_scale']:.3f}x, Rate: {emotion_params['rate_scale']:.3f}x, Energy: {emotion_params['energy_scale']:.3f}x")
    print(f"   Intensity Curve: {emotion_params['intensity_curve']:.3f}")

    # TTS
    try:
        audio = tts.generate(
            text=response['text'],
            emotion_params=emotion_params,
            prosodic_text=response['prosodic_text'],
            emotional_state=response.get('emotional_state')
        )

        duration = len(audio) / 24000
        peak = audio.abs().max().item()
        rms = torch.sqrt(torch.mean(audio**2)).item()

        print(f"\nAUDIO:")
        print(f"   Duration: {duration:.2f}s")
        print(f"   Peak: {peak:.3f}, RMS: {rms:.3f}")
        
        # Save
        output_dir = Path("output/scenarios")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"scenario_{num}_{response['emotion']}.wav"
        torchaudio.save(str(output_file), audio.unsqueeze(0), 24000)
        print(f"   Saved: {output_file.name}")

        return True
    except Exception as e:
        print(f"\nAudio Error: {e}")
        return False

def main():
    print("\n" + "="*70)
    print("  TESTING 5 SCENARIOS - ALL ENHANCEMENTS")
    print("="*70)

    # Initialize
    print("\nInitializing components...")
    brain = OviyaBrain(ollama_url="https://a5d8ea84fc0ff4.lhr.life/api/generate")
    controller = EmotionController()
    tts = HybridVoiceEngine(
        csm_url="https://astronomy-initiative-paso-cream.trycloudflare.com/generate",
        default_engine="csm"
    )
    print("Ready!\n")
    
    # 5 diverse scenarios
    scenarios = [
        (1, "Stressed → Backchannel + Comforting", 
         "I'm really stressed about my presentation tomorrow", 
         "anxious"),
        
        (2, "Excited → High Energy + Smile Markers",
         "Guess what! I just got promoted to team lead!",
         "excited"),
        
        (3, "Uncertain → Epistemic Prosody + Thinking",
         "I'm not sure if I should take this job offer, maybe I should wait?",
         "uncertain"),
        
        (4, "Narrative → Micro-pauses + Memory",
         "So then I talked to my manager, and she said I could work remotely",
         "neutral"),
        
        (5, "Grateful → Warmth + Affection",
         "Thank you so much for always being there, you really help me",
         "grateful")
    ]
    
    results = []
    for scenario in scenarios:
        success = test_scenario(scenario[0], scenario[1], scenario[2], scenario[3], brain, controller, tts)
        results.append(success)
    
    # Summary
    print(f"\n{'='*70}")
    print("  RESULTS SUMMARY")
    print('='*70)

    successful = sum(results)
    print(f"\nSuccessful: {successful}/5")
    print(f"Success Rate: {(successful/5*100):.0f}%")

    print("\nFeatures Demonstrated:")
    print("   - Backchannels (negative_resonance, positive_resonance, thinking)")
    print("   - 49-Emotion Library (all 3 tiers)")
    print("   - Intensity Curves (non-linear scaling)")
    print("   - Prosody Memory (cross-turn consistency)")
    print("   - Micro-pauses (conjunctions, phrases)")
    print("   - Epistemic Prosody (uncertainty detection)")
    print("   - Enhanced Breath System (respiratory model)")
    print("   - Emotional Memory (energy, pace, warmth)")

    print(f"\nAll audio saved to: output/scenarios/")
    print("\nAll Beyond-Maya enhancements working perfectly!\n")

if __name__ == "__main__":
    main()


